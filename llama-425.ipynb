{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!!pip install torch transformers tensorly","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T17:38:48.134025Z","iopub.execute_input":"2025-03-30T17:38:48.134309Z","iopub.status.idle":"2025-03-30T17:38:53.181969Z","shell.execute_reply.started":"2025-03-30T17:38:48.134277Z","shell.execute_reply":"2025-03-30T17:38:53.181054Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"['Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)',\n 'Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)',\n 'Collecting tensorly',\n '  Downloading tensorly-0.9.0-py3-none-any.whl.metadata (8.6 kB)',\n 'Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)',\n 'Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)',\n 'Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)',\n 'Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)',\n 'Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)',\n 'Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)',\n 'Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)',\n 'Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)',\n 'Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)',\n 'Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)',\n 'Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)',\n 'Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)',\n 'Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)',\n 'Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)',\n 'Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)',\n 'Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)',\n 'Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tensorly) (1.13.1)',\n 'Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)',\n 'Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)',\n 'Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)',\n 'Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)',\n 'Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)',\n 'Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)',\n 'Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)',\n 'Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)',\n 'Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)',\n 'Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)',\n 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)',\n 'Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)',\n 'Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)',\n 'Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)',\n 'Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)',\n 'Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)',\n 'Downloading tensorly-0.9.0-py3-none-any.whl (7.4 MB)',\n '   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7.4/7.4 MB 55.2 MB/s eta 0:00:00',\n 'Installing collected packages: tensorly',\n 'Successfully installed tensorly-0.9.0']"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\n# Load the tokenizer and model\nmodel_name = \"cerebras/Cerebras-GPT-111M\"  # Choose the model size\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\n# Move the model to GPU (if available)\nmodel.to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T17:38:53.182736Z","iopub.execute_input":"2025-03-30T17:38:53.182959Z","iopub.status.idle":"2025-03-30T17:39:17.619850Z","shell.execute_reply.started":"2025-03-30T17:38:53.182940Z","shell.execute_reply":"2025-03-30T17:39:17.618915Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/359 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"000ddae9944743059cb071d63bfd7be2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a72f8b8cf3d84292916fa0401dca5c4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3132bde0fdf6434abfef272275b05393"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/486M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bde565e6a2224a9b83dc5a5045174716"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(2048, 768)\n    (drop): Dropout(p=0.0, inplace=False)\n    (h): ModuleList(\n      (0-9): 10 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2SdpaAttention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): GELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T17:39:17.620966Z","iopub.execute_input":"2025-03-30T17:39:17.622026Z","iopub.status.idle":"2025-03-30T17:39:21.093152Z","shell.execute_reply.started":"2025-03-30T17:39:17.621999Z","shell.execute_reply":"2025-03-30T17:39:21.092051Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"cerebras/Cerebras-GPT-6.7B\")\n\n# Set the padding token\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token\n\n# Load a dataset (e.g., wikitext for language modeling)\ndataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n\n# Tokenize the dataset\ndef tokenize_function(examples):\n    tokenized = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n    tokenized[\"labels\"] = tokenized[\"input_ids\"]  # Add labels\n    return tokenized\n\n# Apply tokenization\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\n# Set format for PyTorch (include labels)\ntokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\n# Verify the dataset\nprint(tokenized_dataset[\"train\"][0].keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T17:39:21.095265Z","iopub.execute_input":"2025-03-30T17:39:21.095559Z","iopub.status.idle":"2025-03-30T17:39:40.570554Z","shell.execute_reply.started":"2025-03-30T17:39:21.095535Z","shell.execute_reply":"2025-03-30T17:39:40.569700Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/361 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0186b2b31ee4a558d1b4894354d85f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"746c82c266604cbcb2608bb1e2a4ae05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20d68af89aea451ea4e1d358f0a33973"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d894f087afc492db0598717199393e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/733k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebee893595b54055bb779c4572a0d08e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/6.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e77922b0010443c4a55e2d5a931c11ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/657k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b5afd5f1e8f4c97b98357548dcaea83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4ffb5b5f2fe446baf886c81c32dc827"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cb727531c974d8d9f9ea1b668377b24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d1dff24c9b44018a302af9e592f04c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4358 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6988504ab9314241a2e7aa867e854acd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/36718 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb000b7d874c4be4b65b7a2d0feee1d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce370c6c191042c5805d91e1dfba7f64"}},"metadata":{}},{"name":"stdout","text":"dict_keys(['input_ids', 'attention_mask', 'labels'])\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Create dataloaders\ntrain_dataloader = DataLoader(tokenized_dataset[\"train\"], batch_size=8, shuffle=True)\nval_dataloader = DataLoader(tokenized_dataset[\"validation\"], batch_size=8)\ntest_dataloader = DataLoader(tokenized_dataset[\"test\"], batch_size=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T17:39:40.572279Z","iopub.execute_input":"2025-03-30T17:39:40.572509Z","iopub.status.idle":"2025-03-30T17:39:40.576834Z","shell.execute_reply.started":"2025-03-30T17:39:40.572489Z","shell.execute_reply":"2025-03-30T17:39:40.575994Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!pip install tdqm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T17:39:40.577701Z","iopub.execute_input":"2025-03-30T17:39:40.577962Z","iopub.status.idle":"2025-03-30T17:39:46.957142Z","shell.execute_reply.started":"2025-03-30T17:39:40.577942Z","shell.execute_reply":"2025-03-30T17:39:46.956296Z"}},"outputs":[{"name":"stdout","text":"Collecting tdqm\n  Downloading tdqm-0.0.1.tar.gz (1.4 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tdqm) (4.67.1)\nBuilding wheels for collected packages: tdqm\n  Building wheel for tdqm (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for tdqm: filename=tdqm-0.0.1-py3-none-any.whl size=1320 sha256=ec47ccb8698ada0e456adf47a36a811ad19c8ecd494975c175acaeae6ccd17fe\n  Stored in directory: /root/.cache/pip/wheels/37/31/b8/7b711038035720ba0df14376af06e5e76b9bd61759c861ad92\nSuccessfully built tdqm\nInstalling collected packages: tdqm\nSuccessfully installed tdqm-0.0.1\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import time\nimport psutil\nimport torch\nfrom tqdm import tqdm  # Import tqdm\n\n# Define the device (GPU or CPU)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Function to measure energy and time\ndef measure_energy_and_time(model, dataloader, mode=\"train\"):\n    start_time = time.time()\n    cpu_start = psutil.cpu_percent(interval=None)\n    gpu_start = torch.cuda.memory_allocated() if device == \"cuda\" else 0\n\n    if mode == \"train\":\n        model.train()\n        optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n        for batch in tqdm(dataloader, desc=\"Training\", unit=\"batch\"):  # Add tqdm\n            inputs = batch[\"input_ids\"].to(device)\n            outputs = model(inputs, labels=inputs)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n    elif mode == \"validate\" or mode == \"test\":\n        model.eval()\n        with torch.no_grad():\n            for batch in tqdm(dataloader, desc=\"Validation\" if mode == \"validate\" else \"Testing\", unit=\"batch\"):  # Add tqdm\n                inputs = batch[\"input_ids\"].to(device)\n                outputs = model(inputs, labels=inputs)\n                loss = outputs.loss\n\n    end_time = time.time()\n    cpu_end = psutil.cpu_percent(interval=None)\n    gpu_end = torch.cuda.memory_allocated() if device == \"cuda\" else 0\n\n    # Calculate metrics\n    elapsed_time = end_time - start_time\n    cpu_usage = cpu_end - cpu_start\n    gpu_usage = (gpu_end - gpu_start) / (1024 ** 2)  # Convert to MB\n\n    return elapsed_time, cpu_usage, gpu_usage\n\n# Benchmark training\ntrain_time, train_cpu, train_gpu = measure_energy_and_time(model, train_dataloader, mode=\"train\")\nprint(f\"Training Time: {train_time:.2f} seconds, CPU Usage: {train_cpu}%, GPU Usage: {train_gpu:.2f} MB\")\n\n# Benchmark validation\nval_time, val_cpu, val_gpu = measure_energy_and_time(model, val_dataloader, mode=\"validate\")\nprint(f\"Validation Time: {val_time:.2f} seconds, CPU Usage: {val_cpu}%, GPU Usage: {val_gpu:.2f} MB\")\n\n# Benchmark testing\ntest_time, test_cpu, test_gpu = measure_energy_and_time(model, test_dataloader, mode=\"test\")\nprint(f\"Testing Time: {test_time:.2f} seconds, CPU Usage: {test_cpu}%, GPU Usage: {test_gpu:.2f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T17:39:46.958135Z","iopub.execute_input":"2025-03-30T17:39:46.958376Z","iopub.status.idle":"2025-03-30T18:17:29.666444Z","shell.execute_reply.started":"2025-03-30T17:39:46.958355Z","shell.execute_reply":"2025-03-30T18:17:29.665653Z"}},"outputs":[{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4590/4590 [35:21<00:00,  2.16batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Time: 2121.29 seconds, CPU Usage: 1.2000000000000028%, GPU Usage: 1738.97 MB\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 470/470 [01:05<00:00,  7.17batch/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Time: 65.60 seconds, CPU Usage: -72.9%, GPU Usage: 1146.03 MB\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 545/545 [01:15<00:00,  7.19batch/s]","output_type":"stream"},{"name":"stdout","text":"Testing Time: 75.81 seconds, CPU Usage: 27.0%, GPU Usage: 858.97 MB\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Prepare a single batch for inference\nbatch = next(iter(test_dataloader))\ninputs = batch[\"input_ids\"].to(device)\n\n# Measure inference\nstart_time = time.time()\ncpu_start = psutil.cpu_percent(interval=None)\ngpu_start = torch.cuda.memory_allocated() if device == \"cuda\" else 0\n\nwith torch.no_grad():\n    outputs = model(inputs)\n\nend_time = time.time()\ncpu_end = psutil.cpu_percent(interval=None)\ngpu_end = torch.cuda.memory_allocated() if device == \"cuda\" else 0\n\n# Calculate metrics\ninference_time = end_time - start_time\ncpu_usage = cpu_end - cpu_start\ngpu_usage = (gpu_end - gpu_start) / (1024 ** 2)  # Convert to MB\n\nprint(f\"Inference Time: {inference_time:.2f} seconds, CPU Usage: {cpu_usage}%, GPU Usage: {gpu_usage:.2f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:17:29.667356Z","iopub.execute_input":"2025-03-30T18:17:29.667620Z","iopub.status.idle":"2025-03-30T18:17:29.772269Z","shell.execute_reply.started":"2025-03-30T18:17:29.667580Z","shell.execute_reply":"2025-03-30T18:17:29.771563Z"}},"outputs":[{"name":"stdout","text":"Inference Time: 0.01 seconds, CPU Usage: -28.6%, GPU Usage: 1146.00 MB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\nresults = {\n    \"Training\": {\"Time\": train_time, \"CPU Usage\": train_cpu, \"GPU Usage\": train_gpu},\n    \"Validation\": {\"Time\": val_time, \"CPU Usage\": val_cpu, \"GPU Usage\": val_gpu},\n    \"Testing\": {\"Time\": test_time, \"CPU Usage\": test_cpu, \"GPU Usage\": test_gpu},\n    \"Inference\": {\"Time\": inference_time, \"CPU Usage\": cpu_usage, \"GPU Usage\": gpu_usage},\n}\n\ndf = pd.DataFrame(results)\nprint(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:17:29.772969Z","iopub.execute_input":"2025-03-30T18:17:29.773166Z","iopub.status.idle":"2025-03-30T18:17:29.792373Z","shell.execute_reply.started":"2025-03-30T18:17:29.773149Z","shell.execute_reply":"2025-03-30T18:17:29.791683Z"}},"outputs":[{"name":"stdout","text":"              Training   Validation     Testing    Inference\nTime       2121.291219    65.595345   75.806017     0.005796\nCPU Usage     1.200000   -72.900000   27.000000   -28.600000\nGPU Usage  1738.971191  1146.031738  858.973145  1146.000000\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def calculate_accuracy(model, dataloader):\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Calculating Accuracy\", unit=\"batch\"):\n            inputs = batch[\"input_ids\"].to(device)\n            labels = inputs  # For next-token prediction, labels are the same as inputs\n            outputs = model(inputs)\n            predictions = outputs.logits.argmax(dim=-1)  # Get predicted token IDs\n            correct += (predictions == labels).sum().item()\n            total += labels.numel()\n\n    accuracy = correct / total\n    return accuracy\n\n# Calculate accuracy for the test set\ntest_accuracy = calculate_accuracy(model, test_dataloader)\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:17:29.793176Z","iopub.execute_input":"2025-03-30T18:17:29.793442Z","iopub.status.idle":"2025-03-30T18:18:43.063608Z","shell.execute_reply.started":"2025-03-30T18:17:29.793409Z","shell.execute_reply":"2025-03-30T18:18:43.062827Z"}},"outputs":[{"name":"stderr","text":"Calculating Accuracy: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 545/545 [01:13<00:00,  7.44batch/s]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.8743\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def calculate_loss(model, dataloader):\n    model.eval()\n    total_loss = 0\n    total_samples = 0\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Calculating Loss\", unit=\"batch\"):\n            inputs = batch[\"input_ids\"].to(device)\n            outputs = model(inputs, labels=inputs)\n            loss = outputs.loss\n            total_loss += loss.item() * inputs.size(0)  # Multiply by batch size\n            total_samples += inputs.size(0)\n\n    avg_loss = total_loss / total_samples\n    return avg_loss\n\n# Calculate loss for the test set\ntest_loss = calculate_loss(model, test_dataloader)\nprint(f\"Test Loss: {test_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:18:43.064400Z","iopub.execute_input":"2025-03-30T18:18:43.064662Z","iopub.status.idle":"2025-03-30T18:20:00.367599Z","shell.execute_reply.started":"2025-03-30T18:18:43.064613Z","shell.execute_reply":"2025-03-30T18:20:00.366739Z"}},"outputs":[{"name":"stderr","text":"Calculating Loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 545/545 [01:17<00:00,  7.05batch/s]","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.4841\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Access the first transformer block\ntransformer_block = model.transformer.h[0]\n\n# Extract the combined query, key, and value weights\ncombined_weights = transformer_block.attn.c_attn.weight.data\nprint(\"Combined weights shape:\", combined_weights.shape)\n\n# Split the combined weights into query, key, and value weights\nembed_dim = model.config.hidden_size\nnum_heads = model.config.num_attention_heads\nhead_dim = embed_dim // num_heads\n\nquery_weights = combined_weights[:embed_dim, :]\nkey_weights = combined_weights[embed_dim:2*embed_dim, :]\nvalue_weights = combined_weights[2*embed_dim:, :]\n\nprint(\"Query weights shape:\", query_weights.shape)\nprint(\"Key weights shape:\", key_weights.shape)\nprint(\"Value weights shape:\", value_weights.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:20:00.368427Z","iopub.execute_input":"2025-03-30T18:20:00.368682Z","iopub.status.idle":"2025-03-30T18:20:00.375674Z","shell.execute_reply.started":"2025-03-30T18:20:00.368650Z","shell.execute_reply":"2025-03-30T18:20:00.374888Z"}},"outputs":[{"name":"stdout","text":"Combined weights shape: torch.Size([768, 2304])\nQuery weights shape: torch.Size([768, 2304])\nKey weights shape: torch.Size([0, 2304])\nValue weights shape: torch.Size([0, 2304])\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(\"Query weights shape:\", query_weights.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:20:00.378288Z","iopub.execute_input":"2025-03-30T18:20:00.378489Z","iopub.status.idle":"2025-03-30T18:20:00.389865Z","shell.execute_reply.started":"2025-03-30T18:20:00.378471Z","shell.execute_reply":"2025-03-30T18:20:00.389134Z"}},"outputs":[{"name":"stdout","text":"Query weights shape: torch.Size([768, 2304])\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Reshape the query weights for decomposition\ntensor = query_weights.reshape(128, 128, 108)  # Reshape to 3D\nprint(\"Reshaped tensor shape:\", tensor.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:20:00.390934Z","iopub.execute_input":"2025-03-30T18:20:00.391173Z","iopub.status.idle":"2025-03-30T18:20:00.405059Z","shell.execute_reply.started":"2025-03-30T18:20:00.391153Z","shell.execute_reply":"2025-03-30T18:20:00.404425Z"}},"outputs":[{"name":"stdout","text":"Reshaped tensor shape: torch.Size([128, 128, 108])\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import tensorly as tl\nfrom tensorly.decomposition import parafac\n\n# Set the backend to PyTorch\ntl.set_backend(\"pytorch\")\n\n# Perform CP decomposition\nrank = 5  # Choose the rank for decomposition\nfactors = parafac(tensor, rank=rank)\n\n# Reconstruct the tensor from factors\nreconstructed_tensor = tl.cp_to_tensor(factors)\n\nprint(\"Original tensor shape:\", tensor.shape)\nprint(\"Reconstructed tensor shape:\", reconstructed_tensor.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:20:00.405918Z","iopub.execute_input":"2025-03-30T18:20:00.406155Z","iopub.status.idle":"2025-03-30T18:20:01.304207Z","shell.execute_reply.started":"2025-03-30T18:20:00.406136Z","shell.execute_reply":"2025-03-30T18:20:01.303388Z"}},"outputs":[{"name":"stdout","text":"Original tensor shape: torch.Size([128, 128, 108])\nReconstructed tensor shape: torch.Size([128, 128, 108])\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Reshape the reconstructed tensor back to the original shape\nreconstructed_query_weights = reconstructed_tensor.reshape(query_weights.shape)\nprint(\"Reconstructed query weights shape:\", reconstructed_query_weights.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:20:01.305178Z","iopub.execute_input":"2025-03-30T18:20:01.305503Z","iopub.status.idle":"2025-03-30T18:20:01.310189Z","shell.execute_reply.started":"2025-03-30T18:20:01.305469Z","shell.execute_reply":"2025-03-30T18:20:01.309323Z"}},"outputs":[{"name":"stdout","text":"Reconstructed query weights shape: torch.Size([768, 2304])\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Replace the query weights in the model\ncombined_weights[:768, :] = reconstructed_query_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:20:01.310935Z","iopub.execute_input":"2025-03-30T18:20:01.311175Z","iopub.status.idle":"2025-03-30T18:20:01.326554Z","shell.execute_reply.started":"2025-03-30T18:20:01.311154Z","shell.execute_reply":"2025-03-30T18:20:01.325981Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"!pip install tensorboard","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:20:01.327472Z","iopub.execute_input":"2025-03-30T18:20:01.327774Z","iopub.status.idle":"2025-03-30T18:20:04.686515Z","shell.execute_reply.started":"2025-03-30T18:20:01.327743Z","shell.execute_reply":"2025-03-30T18:20:04.685653Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\nRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.12.0->tensorboard) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.12.0->tensorboard) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.12.0->tensorboard) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.12.0->tensorboard) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.12.0->tensorboard) (2024.2.0)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import torch\n\n# Clear GPU memory\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:20:04.687677Z","iopub.execute_input":"2025-03-30T18:20:04.688019Z","iopub.status.idle":"2025-03-30T18:20:04.792369Z","shell.execute_reply.started":"2025-03-30T18:20:04.687987Z","shell.execute_reply":"2025-03-30T18:20:04.791714Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import time\nimport psutil\nimport torch\nfrom transformers import Trainer, TrainingArguments\n\n# Define training arguments without evaluation\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=2,\n    per_device_train_batch_size=1,  # Reduced batch size\n    save_steps=10_000,\n    save_total_limit=2,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    report_to=\"tensorboard\",\n    fp16=True,  # Enable mixed precision training\n    gradient_accumulation_steps=16,  # Increased gradient accumulation steps\n    disable_tqdm=False,\n    evaluation_strategy=\"no\",  # Disable evaluation entirely\n    load_best_model_at_end=False,  # Disabled since no evaluation\n)\n\n# Define the Trainer without evaluation metrics/datasets\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    # eval_dataset removed\n    # compute_metrics removed\n)\n\n# Debug: Print a message before starting training\nprint(\"Starting fine-tuning...\")\n\n# Measure CPU/GPU usage before training\ncpu_start = psutil.cpu_percent(interval=None)\ngpu_start = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0\n\n# Start timer\nstart_time = time.time()\n\n# Start fine-tuning\ntrainer.train()\n\n# Stop timer\nend_time = time.time()\n\n# Measure CPU/GPU usage after training\ncpu_end = psutil.cpu_percent(interval=None)\ngpu_end = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0\n\n# Calculate metrics\ntraining_time = end_time - start_time\ncpu_usage = cpu_end - cpu_start\ngpu_usage = (gpu_end - gpu_start) / (1024 ** 2)  # Convert to MB\n\n# Debug: Print a message after training completes\nprint(\"Fine-tuning completed!\")\nprint(f\"Training Time: {training_time:.2f} seconds\")\nprint(f\"CPU Usage: {cpu_usage}%\")\nprint(f\"GPU Usage: {gpu_usage:.2f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:20:04.793218Z","iopub.execute_input":"2025-03-30T18:20:04.793437Z","iopub.status.idle":"2025-03-30T20:19:56.312127Z","shell.execute_reply.started":"2025-03-30T18:20:04.793419Z","shell.execute_reply":"2025-03-30T20:19:56.311356Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Starting fine-tuning...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4588' max='4588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4588/4588 1:59:47, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.440600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.422700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.403100</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.434500</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.394100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.409900</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.407600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.373300</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.427000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.414200</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.405600</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.389100</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.406500</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.405500</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.381000</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.417400</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.408400</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.419700</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.389700</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.400000</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.394600</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.425100</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.376800</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.348300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.332300</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.347400</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.347600</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.345200</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.357600</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.334200</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.359400</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.334000</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.349100</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.338300</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.327700</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.347400</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.337300</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.324300</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>0.337800</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.326600</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>0.369400</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.348900</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>0.352300</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.342300</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.336500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Fine-tuning completed!\nTraining Time: 7189.80 seconds\nCPU Usage: -0.1999999999999993%\nGPU Usage: 851.02 MB\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}